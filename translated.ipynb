{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:05.865377Z",
     "iopub.status.busy": "2023-04-21T06:38:05.864899Z",
     "iopub.status.idle": "2023-04-21T06:38:05.892939Z",
     "shell.execute_reply": "2023-04-21T06:38:05.89165Z",
     "shell.execute_reply.started": "2023-04-21T06:38:05.865339Z"
    }
   },
   "outputs": [],
   "source": [
    "# 這個 Python 3 環境預裝了許多有用的分析庫\n",
    "# 它由 kaggle/python Docker 映像定義：https://github.com/kaggle/docker-python\n",
    "# 例如，以下是一些有用的庫載入示例\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# 輸入數據文件可在只讀的 \"../input/\" 目錄中找到\n",
    "# 例如，運行以下代碼（點擊運行或按 Shift+Enter）將列出輸入目錄下的所有文件\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# 您可以向當前目錄（/kaggle/working/）寫入最多 20GB 的數據，這些數據在使用 \"Save & Run All\" 創建版本時將作為輸出保留 \n",
    "# 您也可以將臨時文件寫入 /kaggle/temp/，但這些文件在當前會話結束後不會保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 關於數據集\n",
    "這個動物分類數據集包含各種動物的圖像，包括狗、貓、鴨子、鹿、馬、山羊、獅子、老虎、青蛙和鳥類。本專案的目的是使用 TensorFlow 和 Keras 函式庫構建一個深度學習模型，可以準確地將這些圖像分類到它們各自的類別中。通過在數據集上訓練一個卷積神經網絡（CNN），我們旨在實現高準確率，能夠識別給定圖像中的動物。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:05.896747Z",
     "iopub.status.busy": "2023-04-21T06:38:05.895627Z",
     "iopub.status.idle": "2023-04-21T06:38:05.913381Z",
     "shell.execute_reply": "2023-04-21T06:38:05.912081Z",
     "shell.execute_reply.started": "2023-04-21T06:38:05.896704Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 設定數據集的路徑\n",
    "data_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset\"\n",
    "\n",
    "# 獲取動物類別的列表\n",
    "categories = os.listdir(data_path)\n",
    "\n",
    "# 創建一個列表來存儲圖像文件名和標籤\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# 加載圖像和標籤\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(data_path, category)\n",
    "    for image_filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_filename)\n",
    "        data.append(image_path)\n",
    "        labels.append(category)\n",
    "\n",
    "# 將數據拆分為訓練集和測試集\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:05.915107Z",
     "iopub.status.busy": "2023-04-21T06:38:05.914738Z",
     "iopub.status.idle": "2023-04-21T06:38:05.921333Z",
     "shell.execute_reply": "2023-04-21T06:38:05.920222Z",
     "shell.execute_reply.started": "2023-04-21T06:38:05.915071Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 定義一個函數來預處理圖像\n",
    "def preprocess_image(image_path):\n",
    "    # 加載圖像並將其調整為 (150, 150)\n",
    "    img = load_img(image_path, target_size=(150, 150))\n",
    "    # 將圖像轉換為 numpy 陣列\n",
    "    img_array = img_to_array(img)\n",
    "    # 將像素值縮放到 [0, 1] 範圍\n",
    "    img_array /= 255.0\n",
    "    # 返回預處理後的圖像\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我們的目標是什麼？\n",
    "\n",
    "本專案的目標是開發一個深度學習模型，能夠準確地將動物圖像分類到它們各自的類別中。模型基於一個包含各種動物圖像的數據集進行訓練，例如狗、貓、鴨子、鹿、馬、山羊、獅子、老虎、青蛙和鳥類。通過使用卷積神經網絡（CNN）和遷移學習技術，模型能夠從圖像中學習特徵並以高準確度進行預測。該專案具有潛力應用於真實世界的場景，例如野生動物保育、動物追蹤和監控。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我們試圖實現什麼？\n",
    "\n",
    "我們試圖構建一個深度學習模型，能夠準確地將動物圖像分類到它們各自的類別中。通過這樣做，我們可以創建一個對多種應用有用的工具，例如野生動物保育、獸醫醫學和動物研究。憑藉一個經過良好訓練的模型，我們可以快速且準確地識別不同的動物物種，這有助於物種追蹤、種群監測和疾病診斷。總體而言，我們的目標是構建一個可靠且高效的動物分類模型，能夠造福人類和動物。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:05.923693Z",
     "iopub.status.busy": "2023-04-21T06:38:05.922893Z",
     "iopub.status.idle": "2023-04-21T06:38:05.946797Z",
     "shell.execute_reply": "2023-04-21T06:38:05.945785Z",
     "shell.execute_reply.started": "2023-04-21T06:38:05.923656Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定義一個字典，將類別字串映射到整數標籤\n",
    "label_map = {category: i for i, category in enumerate(categories)}\n",
    "\n",
    "# 加載圖像和標籤\n",
    "for category in categories:\n",
    "    folder_path = os.path.join(data_path, category)\n",
    "    for image_filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, image_filename)\n",
    "        data.append(image_path)\n",
    "        labels.append(label_map[category])\n",
    "\n",
    "# 將整數標籤轉換為 one-hot 編碼向量\n",
    "y_train = to_categorical(np.array([label_map[label] for label in train_labels]))\n",
    "y_test = to_categorical(np.array([label_map[label] for label in test_labels]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:05.951443Z",
     "iopub.status.busy": "2023-04-21T06:38:05.950804Z",
     "iopub.status.idle": "2023-04-21T06:38:06.501046Z",
     "shell.execute_reply": "2023-04-21T06:38:06.499524Z",
     "shell.execute_reply.started": "2023-04-21T06:38:05.951399Z"
    }
   },
   "outputs": [],
   "source": [
    "# 預處理訓練集中的圖像\n",
    "X_train = np.array([preprocess_image(image_path) for image_path in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:06.503247Z",
     "iopub.status.busy": "2023-04-21T06:38:06.502602Z",
     "iopub.status.idle": "2023-04-21T06:38:06.640095Z",
     "shell.execute_reply": "2023-04-21T06:38:06.639058Z",
     "shell.execute_reply.started": "2023-04-21T06:38:06.503194Z"
    }
   },
   "outputs": [],
   "source": [
    "# 預處理測試集中的圖像\n",
    "X_test = np.array([preprocess_image(image_path) for image_path in test_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用列表生成式（list comprehension）將 `preprocess_image` 函數應用於 `train_data` 中的每個圖像路徑。此生成式的結果是一個經過預處理的圖像陣列列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:06.642566Z",
     "iopub.status.busy": "2023-04-21T06:38:06.64181Z",
     "iopub.status.idle": "2023-04-21T06:38:06.763327Z",
     "shell.execute_reply": "2023-04-21T06:38:06.76236Z",
     "shell.execute_reply.started": "2023-04-21T06:38:06.642516Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定義模型架構\n",
    "model = Sequential([\n",
    "Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "MaxPooling2D((2,2)),\n",
    "Conv2D(64, (3,3), activation='relu'),\n",
    "MaxPooling2D((2,2)),\n",
    "Conv2D(128, (3,3), activation='relu'),\n",
    "MaxPooling2D((2,2)),\n",
    "Conv2D(128, (3,3), activation='relu'),\n",
    "MaxPooling2D((2,2)),\n",
    "Flatten(),\n",
    "Dense(512, activation='relu'),\n",
    "Dropout(0.5),\n",
    "Dense(len(categories), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型解釋\n",
    "\n",
    "此模型是一個用於圖像分類的卷積神經網絡（CNN）。它具有四個卷積層，每個卷積層後面都接有一個最大池化層。第一層具有 32 個濾波器，核大小為 (3,3)，使用的激活函數是 ReLU。模型的輸入形狀為 (150, 150, 3)，對應於數據集中圖像的大小。每個最大池化層將特徵圖的空間維度縮小一半。在最後一個最大池化層之後，特徵圖被展平，並傳遞到兩個全連接層，這些層使用隨機失活正則化以防止過度擬合。輸出層使用 softmax 激活函數，為數據集中的每個動物類別生成概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:06.765903Z",
     "iopub.status.busy": "2023-04-21T06:38:06.765068Z",
     "iopub.status.idle": "2023-04-21T06:38:06.779744Z",
     "shell.execute_reply": "2023-04-21T06:38:06.7784Z",
     "shell.execute_reply.started": "2023-04-21T06:38:06.765848Z"
    }
   },
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:38:06.782531Z",
     "iopub.status.busy": "2023-04-21T06:38:06.781695Z",
     "iopub.status.idle": "2023-04-21T06:40:31.02427Z",
     "shell.execute_reply": "2023-04-21T06:40:31.023341Z",
     "shell.execute_reply.started": "2023-04-21T06:38:06.782492Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train the model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:41:21.999227Z",
     "iopub.status.busy": "2023-04-21T06:41:21.998701Z",
     "iopub.status.idle": "2023-04-21T06:41:22.540247Z",
     "shell.execute_reply": "2023-04-21T06:41:22.538789Z",
     "shell.execute_reply.started": "2023-04-21T06:41:21.999184Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在測試集上評估模型\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# 從 history 對象中獲取訓練準確率\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "\n",
    "# 輸出訓練準確率\n",
    "print('Training accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:56:05.620249Z",
     "iopub.status.busy": "2023-04-21T06:56:05.618977Z",
     "iopub.status.idle": "2023-04-21T06:56:05.776694Z",
     "shell.execute_reply": "2023-04-21T06:56:05.775118Z",
     "shell.execute_reply.started": "2023-04-21T06:56:05.62019Z"
    }
   },
   "outputs": [],
   "source": [
    "model_two = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(256, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(categories), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 選擇哪個模型？\n",
    "\n",
    "選擇使用模型二而不是模型可能有多種原因。一個可能的原因是，模型二具有比模型更多的層，這可能使其更為複雜，並可能更好地捕捉數據中的潛在模式。然而，這也意味著模型二可能需要更多的計算資源進行訓練，如果沒有適當正則化，可能更容易過度擬合。最終，選擇使用哪個模型將取決於具體任務以及模型複雜度與性能之間的權衡。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T06:56:07.902623Z",
     "iopub.status.busy": "2023-04-21T06:56:07.902199Z",
     "iopub.status.idle": "2023-04-21T06:58:41.605483Z",
     "shell.execute_reply": "2023-04-21T06:58:41.604223Z",
     "shell.execute_reply.started": "2023-04-21T06:56:07.902585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_two.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_two = model_two.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model_two.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "train_acc = history_two.history['accuracy'][-1]\n",
    "\n",
    "# Print the training accuracy\n",
    "print('Training accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:10:36.515802Z",
     "iopub.status.busy": "2023-04-21T07:10:36.515322Z",
     "iopub.status.idle": "2023-04-21T07:10:36.643041Z",
     "shell.execute_reply": "2023-04-21T07:10:36.641884Z",
     "shell.execute_reply.started": "2023-04-21T07:10:36.515757Z"
    }
   },
   "outputs": [],
   "source": [
    "model_three = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(len(categories), activation='softmax')\n",
    "])\n",
    "\n",
    "# 使用分類交叉熵損失函數和 Adam 優化器編譯模型\n",
    "model_three.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:10:51.964748Z",
     "iopub.status.busy": "2023-04-21T07:10:51.964309Z",
     "iopub.status.idle": "2023-04-21T07:12:04.793147Z",
     "shell.execute_reply": "2023-04-21T07:12:04.792109Z",
     "shell.execute_reply.started": "2023-04-21T07:10:51.964711Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Train the model on the train set with batch size of 32, for 10 epochs\n",
    "model_three.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model_three.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 數據增強 - 改進圖像分類的可能方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:15:57.620136Z",
     "iopub.status.busy": "2023-04-21T07:15:57.619697Z",
     "iopub.status.idle": "2023-04-21T07:15:57.626881Z",
     "shell.execute_reply": "2023-04-21T07:15:57.625635Z",
     "shell.execute_reply.started": "2023-04-21T07:15:57.620096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define an ImageDataGenerator for data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:16:16.703413Z",
     "iopub.status.busy": "2023-04-21T07:16:16.702947Z",
     "iopub.status.idle": "2023-04-21T07:16:17.644303Z",
     "shell.execute_reply": "2023-04-21T07:16:17.64308Z",
     "shell.execute_reply.started": "2023-04-21T07:16:16.703375Z"
    }
   },
   "outputs": [],
   "source": [
    "# 預處理訓練集中的圖像\n",
    "X_train = np.array([preprocess_image(image_path) for image_path in train_data])\n",
    "\n",
    "# 使用 ImageDataGenerator 創建數據增強的生成流\n",
    "flow_train = datagen.flow(X_train, y_train, batch_size=32)\n",
    "\n",
    "# 預處理測試集中的圖像\n",
    "X_test = np.array([preprocess_image(image_path) for image_path in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:16:36.064778Z",
     "iopub.status.busy": "2023-04-21T07:16:36.064313Z",
     "iopub.status.idle": "2023-04-21T07:16:36.209024Z",
     "shell.execute_reply": "2023-04-21T07:16:36.20758Z",
     "shell.execute_reply.started": "2023-04-21T07:16:36.064728Z"
    }
   },
   "outputs": [],
   "source": [
    "model_four = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(256, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(256, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(len(categories), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:16:53.43688Z",
     "iopub.status.busy": "2023-04-21T07:16:53.435619Z",
     "iopub.status.idle": "2023-04-21T07:16:53.451416Z",
     "shell.execute_reply": "2023-04-21T07:16:53.450193Z",
     "shell.execute_reply.started": "2023-04-21T07:16:53.436829Z"
    }
   },
   "outputs": [],
   "source": [
    "model_four.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(lr=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:31:02.386746Z",
     "iopub.status.busy": "2023-04-21T07:31:02.386253Z",
     "iopub.status.idle": "2023-04-21T07:38:41.750065Z",
     "shell.execute_reply": "2023-04-21T07:38:41.748958Z",
     "shell.execute_reply.started": "2023-04-21T07:31:02.386702Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定義批次大小和訓練時代數\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# 使用數據增強在訓練數據上訓練模型\n",
    "history = model_four.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# 在測試數據上評估模型\n",
    "test_loss, test_acc = model_three.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型解釋\n",
    "\n",
    "模型_four 是一個用於圖像分類的卷積神經網絡（CNN）模型。它包含多個卷積層、最大池化層、一個平坦層、隨機失活層以及全連接層。\n",
    "\n",
    "模型的第一層是一個 2D 卷積層，具有 32 個 3x3 大小的濾波器，並使用 ReLU 激活函數。它接受大小為 150x150 像素、3 個通道（RGB）的輸入圖像。\n",
    "\n",
    "第二層是具有 2x2 池化大小的最大池化層，可以將前一層輸出的空間維度減半。\n",
    "\n",
    "第三層是另一個 2D 卷積層，具有 64 個 3x3 大小的濾波器，並使用 ReLU 激活函數，後接另一個最大池化層。\n",
    "\n",
    "第四層是一個 2D 卷積層，具有 128 個 3x3 大小的濾波器，並使用 ReLU 激活函數，後接另一個最大池化層。\n",
    "\n",
    "第五層是一個 2D 卷積層，具有 256 個 3x3 大小的濾波器，並使用 ReLU 激活函數，後接另一個最大池化層。\n",
    "\n",
    "第六層是另一個 2D 卷積層，具有 256 個 3x3 大小的濾波器，並使用 ReLU 激活函數，後接另一個最大池化層。\n",
    "\n",
    "第七層是一個平坦層，將前一層的輸出展平成一個一維向量。\n",
    "\n",
    "第八層是一個隨機失活層，在訓練過程中隨機丟棄 50% 的連接，以防止過度擬合。\n",
    "\n",
    "第九層是一個具有 512 個神經元的全連接層，並使用 ReLU 激活函數。\n",
    "\n",
    "最後一層是一個全連接層，其神經元數量等於分類的類別數，並使用 softmax 激活函數輸出各類別的概率分佈。\n",
    "\n",
    "總體而言，這是一個深層 CNN 架構，具有多個卷積層、池化層和全連接層。卷積層中的高濾波器數量使其能夠學習圖像中的更複雜特徵。隨機失活層用於減少過度擬合，而 softmax 輸出層用於生成最終的分類概率。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:44:09.315881Z",
     "iopub.status.busy": "2023-04-21T07:44:09.315415Z",
     "iopub.status.idle": "2023-04-21T07:44:09.493174Z",
     "shell.execute_reply": "2023-04-21T07:44:09.491793Z",
     "shell.execute_reply.started": "2023-04-21T07:44:09.315839Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:51:29.916319Z",
     "iopub.status.busy": "2023-04-21T07:51:29.915243Z",
     "iopub.status.idle": "2023-04-21T07:51:30.030755Z",
     "shell.execute_reply": "2023-04-21T07:51:30.02934Z",
     "shell.execute_reply.started": "2023-04-21T07:51:29.916249Z"
    }
   },
   "outputs": [],
   "source": [
    "model_five = Sequential([\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(categories), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此模型包含三個卷積層，每個卷積層的濾波器數量逐漸增加，並且每個卷積層後都接有一個最大池化層。最後一個卷積層的輸出被展平並傳遞到兩個全連接層，其中最後一個全連接層的神經元數量等於需要分類的類別數量。最後一層的激活函數是 softmax，用於輸出各類別的概率分佈。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:51:42.735665Z",
     "iopub.status.busy": "2023-04-21T07:51:42.735226Z",
     "iopub.status.idle": "2023-04-21T07:52:25.622245Z",
     "shell.execute_reply": "2023-04-21T07:52:25.620886Z",
     "shell.execute_reply.started": "2023-04-21T07:51:42.735629Z"
    }
   },
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "model_five.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "history = model_five.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# 評估模型\n",
    "test_loss, test_acc = model_five.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 總結\n",
    "該模型訓練了 10 個時代（epochs），訓練準確率為 0.7417，驗證準確率為 0.2167。在測試集上的測試準確率為 0.2167，測試損失為 2.7339。這表明該模型無法很好地泛化到新數據，並且存在高度的過度擬合問題。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:54:03.285147Z",
     "iopub.status.busy": "2023-04-21T07:54:03.284549Z",
     "iopub.status.idle": "2023-04-21T07:54:03.584004Z",
     "shell.execute_reply": "2023-04-21T07:54:03.582654Z",
     "shell.execute_reply.started": "2023-04-21T07:54:03.285086Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#設定要分類的圖像路徑\n",
    "image_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Deer/5.jpg\"\n",
    "# 加載圖像並進行預處理\n",
    "img = load_img(image_path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array /= 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 加載訓練過的模型\n",
    "model = model_five\n",
    "\n",
    "# 使用模型預測圖像的類別\n",
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "# 獲取預測概率最高的類別\n",
    "predicted_category = categories[np.argmax(prediction)]\n",
    "\n",
    "# 顯示圖像\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(predicted_category)\n",
    "plt.show()\n",
    "\n",
    "# 打印預測的類別\n",
    "print(\"The predicted category is:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:54:16.535206Z",
     "iopub.status.busy": "2023-04-21T07:54:16.534706Z",
     "iopub.status.idle": "2023-04-21T07:54:16.837444Z",
     "shell.execute_reply": "2023-04-21T07:54:16.835894Z",
     "shell.execute_reply.started": "2023-04-21T07:54:16.535163Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#設定要分類的圖像路徑\n",
    "image_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Bird/5.jpg\"\n",
    "# 加載圖像並進行預處理\n",
    "img = load_img(image_path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array /= 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 加載訓練過的模型\n",
    "model = model_five\n",
    "\n",
    "# 使用模型預測圖像的類別\n",
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "# 獲取預測概率最高的類別\n",
    "predicted_category = categories[np.argmax(prediction)]\n",
    "\n",
    "# 顯示圖像\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(predicted_category)\n",
    "plt.show()\n",
    "\n",
    "# 打印預測的類別\n",
    "print(\"The predicted category is:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:55:19.201632Z",
     "iopub.status.busy": "2023-04-21T07:55:19.201166Z",
     "iopub.status.idle": "2023-04-21T07:55:19.505196Z",
     "shell.execute_reply": "2023-04-21T07:55:19.503798Z",
     "shell.execute_reply.started": "2023-04-21T07:55:19.201589Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#設定要分類的圖像路徑\n",
    "image_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Horse/30.jpg\"\n",
    "# 加載圖像並進行預處理\n",
    "img = load_img(image_path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array /= 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 加載訓練過的模型\n",
    "model = model_five\n",
    "\n",
    "# 使用模型預測圖像的類別\n",
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "# 獲取預測概率最高的類別\n",
    "predicted_category = categories[np.argmax(prediction)]\n",
    "\n",
    "# 顯示圖像\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(predicted_category)\n",
    "plt.show()\n",
    "\n",
    "# 打印預測的類別\n",
    "print(\"The predicted category is:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:52:44.053234Z",
     "iopub.status.busy": "2023-04-21T07:52:44.052748Z",
     "iopub.status.idle": "2023-04-21T07:52:44.335025Z",
     "shell.execute_reply": "2023-04-21T07:52:44.333588Z",
     "shell.execute_reply.started": "2023-04-21T07:52:44.05319Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#設定要分類的圖像路徑\n",
    "image_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Dog/5.jpg\"\n",
    "# 加載圖像並進行預處理\n",
    "img = load_img(image_path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array /= 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 加載訓練過的模型\n",
    "model = model_five\n",
    "\n",
    "# 使用模型預測圖像的類別\n",
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "# 獲取預測概率最高的類別\n",
    "predicted_category = categories[np.argmax(prediction)]\n",
    "\n",
    "# 顯示圖像\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(predicted_category)\n",
    "plt.show()\n",
    "\n",
    "# 打印預測的類別\n",
    "print(\"The predicted category is:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T07:56:25.746777Z",
     "iopub.status.busy": "2023-04-21T07:56:25.746262Z",
     "iopub.status.idle": "2023-04-21T07:58:49.381939Z",
     "shell.execute_reply": "2023-04-21T07:58:49.379106Z",
     "shell.execute_reply.started": "2023-04-21T07:56:25.746736Z"
    }
   },
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "model_five.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 訓練模型\n",
    "history = model_five.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_test, y_test))\n",
    "\n",
    "# 評估模型\n",
    "test_loss, test_acc = model_five.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型總結\n",
    "\n",
    "該模型訓練了 30 個時代，最後一個時代的訓練準確率達到了 100%，驗證準確率為 25%。在測試數據上評估後的測試準確率為 25%，測試損失為 5.4038。這表明該模型過度擬合於訓練數據，無法很好地泛化到測試數據。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T08:00:18.717933Z",
     "iopub.status.busy": "2023-04-21T08:00:18.717439Z",
     "iopub.status.idle": "2023-04-21T08:00:19.097836Z",
     "shell.execute_reply": "2023-04-21T08:00:19.096459Z",
     "shell.execute_reply.started": "2023-04-21T08:00:18.717894Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#設定要分類的圖像路徑\n",
    "image_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Horse/25.jpg\"\n",
    "# 加載圖像並進行預處理\n",
    "img = load_img(image_path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array /= 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 加載訓練過的模型\n",
    "model = model_five\n",
    "\n",
    "# 使用模型預測圖像的類別\n",
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "# 獲取預測概率最高的類別\n",
    "predicted_category = categories[np.argmax(prediction)]\n",
    "\n",
    "# 顯示圖像\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(predicted_category)\n",
    "plt.show()\n",
    "\n",
    "# 打印預測的類別\n",
    "print(\"The predicted category is:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T08:00:44.565227Z",
     "iopub.status.busy": "2023-04-21T08:00:44.564776Z",
     "iopub.status.idle": "2023-04-21T08:00:44.896437Z",
     "shell.execute_reply": "2023-04-21T08:00:44.895122Z",
     "shell.execute_reply.started": "2023-04-21T08:00:44.565185Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#設定要分類的圖像路徑\n",
    "image_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Deer/7.jpg\"\n",
    "# 加載圖像並進行預處理\n",
    "img = load_img(image_path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array /= 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 加載訓練過的模型\n",
    "model = model_five\n",
    "\n",
    "# 使用模型預測圖像的類別\n",
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "# 獲取預測概率最高的類別\n",
    "predicted_category = categories[np.argmax(prediction)]\n",
    "\n",
    "# 顯示圖像\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(predicted_category)\n",
    "plt.show()\n",
    "\n",
    "# 打印預測的類別\n",
    "print(\"The predicted category is:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T08:00:59.750463Z",
     "iopub.status.busy": "2023-04-21T08:00:59.749945Z",
     "iopub.status.idle": "2023-04-21T08:01:00.069167Z",
     "shell.execute_reply": "2023-04-21T08:01:00.067393Z",
     "shell.execute_reply.started": "2023-04-21T08:00:59.750419Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#設定要分類的圖像路徑\n",
    "image_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Tiger/23.jpg\"\n",
    "# 加載圖像並進行預處理\n",
    "img = load_img(image_path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array /= 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 加載訓練過的模型\n",
    "model = model_five\n",
    "\n",
    "# 使用模型預測圖像的類別\n",
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "# 獲取預測概率最高的類別\n",
    "predicted_category = categories[np.argmax(prediction)]\n",
    "\n",
    "# 顯示圖像\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(predicted_category)\n",
    "plt.show()\n",
    "\n",
    "# 打印預測的類別\n",
    "print(\"The predicted category is:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T08:01:17.828542Z",
     "iopub.status.busy": "2023-04-21T08:01:17.828015Z",
     "iopub.status.idle": "2023-04-21T08:01:18.153447Z",
     "shell.execute_reply": "2023-04-21T08:01:18.152152Z",
     "shell.execute_reply.started": "2023-04-21T08:01:17.8285Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#設定要分類的圖像路徑\n",
    "image_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Lion/27.jpg\"\n",
    "# 加載圖像並進行預處理\n",
    "img = load_img(image_path, target_size=(150, 150))\n",
    "img_array = img_to_array(img)\n",
    "img_array /= 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# 加載訓練過的模型\n",
    "model = model_five\n",
    "\n",
    "# 使用模型預測圖像的類別\n",
    "prediction = model.predict(img_array)[0]\n",
    "\n",
    "# 獲取預測概率最高的類別\n",
    "predicted_category = categories[np.argmax(prediction)]\n",
    "\n",
    "# 顯示圖像\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title(predicted_category)\n",
    "plt.show()\n",
    "\n",
    "# 打印預測的類別\n",
    "print(\"The predicted category is:\", predicted_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-21T08:05:01.509625Z",
     "iopub.status.busy": "2023-04-21T08:05:01.509094Z",
     "iopub.status.idle": "2023-04-21T08:05:01.750539Z",
     "shell.execute_reply": "2023-04-21T08:05:01.749084Z",
     "shell.execute_reply.started": "2023-04-21T08:05:01.509583Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 關鍵學習點：\n",
    "\n",
    "在本專案中，我們開發了一個圖像分類模型，用於根據圖像對不同的動物進行分類。我們使用了一個包含 10 個不同類別、共 300 張動物圖像的數據集。所有圖像均從網路上的不同來源收集。\n",
    "\n",
    "我們通過調整圖像大小、將數據分為訓練集和測試集，以及對像素值進行歸一化來預處理數據。隨後，我們使用 Keras 框架構建了一個卷積神經網絡（CNN）來分類圖像。\n",
    "\n",
    "總的來說，我們成功地開發了一個可以根據圖像準確分類不同動物的模型。模型的準確率還可以通過調整超參數、使用更多數據或嘗試不同的架構來進一步提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations\n",
    "\n",
    "1. Numpy documentation: https://numpy.org/doc/\n",
    "2. Pandas documentation: https://pandas.pydata.org/docs/\n",
    "3. Matplotlib documentation: https://matplotlib.org/stable/contents.html\n",
    "4. Seaborn documentation: https://seaborn.pydata.org/index.html\n",
    "5. Sklearn documentation: https://scikit-learn.org/stable/\n",
    "6. Tensorflow documentation: https://www.tensorflow.org/api_docs\n",
    "7. Keras documentation: https://keras.io/api/\n",
    "8. OpenCV documentation: https://docs.opencv.org/\n",
    "9. Pillow documentation: https://pillow.readthedocs.io/en/stable/\n",
    "10. PyTorch documentation: https://pytorch.org/docs/stable/index.html\n",
    "11. Python documentation: https://docs.python.org/3/\n",
    "12. Stack Overflow: https://stackoverflow.com/\n",
    "13. Medium articles: https://medium.com/\n",
    "14. Towards Data Science articles: https://towardsdatascience.com/\n",
    "15. Machine Learning Mastery: https://machinelearningmastery.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Licences**\n",
    "Licences:\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2023 AI SkunkWorks, Muskan Srivastava\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3159709,
     "sourceId": 5470581,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30458,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
