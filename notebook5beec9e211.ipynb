{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5470581,"sourceType":"datasetVersion","datasetId":3159709}],"dockerImageVersionId":30458,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-21T06:38:05.864899Z","iopub.execute_input":"2023-04-21T06:38:05.865377Z","iopub.status.idle":"2023-04-21T06:38:05.892939Z","shell.execute_reply.started":"2023-04-21T06:38:05.865339Z","shell.execute_reply":"2023-04-21T06:38:05.89165Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# About the Dataset\nThe animal classification dataset consists of images of various animals, including dogs, cats, ducks, deer, horses, goats, lions, tigers, frogs, and birds. The aim of this project is to build a deep learning model using TensorFlow and Keras libraries that can accurately classify these images into their respective categories. By training a convolutional neural network (CNN) on the dataset, we aim to achieve high accuracy in identifying the animal in the given image.","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.utils import to_categorical\n\n# Set the path to the dataset\ndata_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset\"\n\n# Get the list of animal categories\ncategories = os.listdir(data_path)\n\n# Create a list to store the image filenames and labels\ndata = []\nlabels = []\n\n# Load the images and labels\nfor category in categories:\n    folder_path = os.path.join(data_path, category)\n    for image_filename in os.listdir(folder_path):\n        image_path = os.path.join(folder_path, image_filename)\n        data.append(image_path)\n        labels.append(category)\n\n# Split the data into train and test sets\ntrain_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:38:05.895627Z","iopub.execute_input":"2023-04-21T06:38:05.896747Z","iopub.status.idle":"2023-04-21T06:38:05.913381Z","shell.execute_reply.started":"2023-04-21T06:38:05.896704Z","shell.execute_reply":"2023-04-21T06:38:05.912081Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Define a function to preprocess the images\ndef preprocess_image(image_path):\n    # Load the image and resize it to (150, 150)\n    img = load_img(image_path, target_size=(150, 150))\n    # Convert the image to a numpy array\n    img_array = img_to_array(img)\n    # Scale the pixel values to the range of [0, 1]\n    img_array /= 255.0\n    # Return the preprocessed image\n    return img_array","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:38:05.914738Z","iopub.execute_input":"2023-04-21T06:38:05.915107Z","iopub.status.idle":"2023-04-21T06:38:05.921333Z","shell.execute_reply.started":"2023-04-21T06:38:05.915071Z","shell.execute_reply":"2023-04-21T06:38:05.920222Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# What is our Aim?\n\nThe aim of this project is to develop a deep learning model that can accurately classify images of animals into their respective categories. The model is trained on a dataset consisting of images of various animals such as dogs, cats, ducks, deer, horses, goats, lions, tigers, frogs, and birds. By using convolutional neural networks (CNNs) and transfer learning techniques, the model is able to learn features from the images and make predictions with high accuracy. The project has the potential to be used in real-world applications such as wildlife conservation, animal tracking, and monitoring.","metadata":{}},{"cell_type":"markdown","source":"# What are we trying to achieve?\n\nWe are trying to build a deep learning model that can accurately classify images of animals into their respective categories. By doing so, we can create a useful tool for a variety of applications, such as wildlife conservation, veterinary medicine, and animal research. With a well-trained model, we can quickly and accurately identify different species of animals, which can help with species tracking, population monitoring, and disease diagnosis. Overall, our goal is to build a reliable and efficient animal classification model that can benefit both humans and animals.","metadata":{}},{"cell_type":"code","source":"# Define a dictionary that maps category strings to integer labels\nlabel_map = {category: i for i, category in enumerate(categories)}\n\n# Load the images and labels\nfor category in categories:\n    folder_path = os.path.join(data_path, category)\n    for image_filename in os.listdir(folder_path):\n        image_path = os.path.join(folder_path, image_filename)\n        data.append(image_path)\n        labels.append(label_map[category])\n\n# Convert the integer labels to one-hot encoded vectors\ny_train = to_categorical(np.array([label_map[label] for label in train_labels]))\ny_test = to_categorical(np.array([label_map[label] for label in test_labels]))\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:38:05.922893Z","iopub.execute_input":"2023-04-21T06:38:05.923693Z","iopub.status.idle":"2023-04-21T06:38:05.946797Z","shell.execute_reply.started":"2023-04-21T06:38:05.923656Z","shell.execute_reply":"2023-04-21T06:38:05.945785Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocess the images in the train set\nX_train = np.array([preprocess_image(image_path) for image_path in train_data])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:38:05.950804Z","iopub.execute_input":"2023-04-21T06:38:05.951443Z","iopub.status.idle":"2023-04-21T06:38:06.501046Z","shell.execute_reply.started":"2023-04-21T06:38:05.951399Z","shell.execute_reply":"2023-04-21T06:38:06.499524Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Preprocess the images in the test set\nX_test = np.array([preprocess_image(image_path) for image_path in test_data])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:38:06.502602Z","iopub.execute_input":"2023-04-21T06:38:06.503247Z","iopub.status.idle":"2023-04-21T06:38:06.640095Z","shell.execute_reply.started":"2023-04-21T06:38:06.503194Z","shell.execute_reply":"2023-04-21T06:38:06.639058Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Using a list comprehension to apply the preprocess_image function to each image path in train_data. The result of this comprehension is a list of preprocessed image arrays.","metadata":{}},{"cell_type":"code","source":"#Define the model architecture\nmodel = Sequential([\nConv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\nMaxPooling2D((2,2)),\nConv2D(64, (3,3), activation='relu'),\nMaxPooling2D((2,2)),\nConv2D(128, (3,3), activation='relu'),\nMaxPooling2D((2,2)),\nConv2D(128, (3,3), activation='relu'),\nMaxPooling2D((2,2)),\nFlatten(),\nDense(512, activation='relu'),\nDropout(0.5),\nDense(len(categories), activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:38:06.64181Z","iopub.execute_input":"2023-04-21T06:38:06.642566Z","iopub.status.idle":"2023-04-21T06:38:06.763327Z","shell.execute_reply.started":"2023-04-21T06:38:06.642516Z","shell.execute_reply":"2023-04-21T06:38:06.76236Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Explanation:\nThis model is a convolutional neural network (CNN) used for image classification. It has four convolutional layers, each followed by a max pooling layer. The first layer has 32 filters with a kernel size of 3x3, the second has 64 filters with a kernel size of 3x3, the third has 128 filters with a kernel size of 3x3, and the fourth has 128 filters with a kernel size of 3x3. The output of the last max pooling layer is flattened and then passed through two dense layers with ReLU activation. The first dense layer has 512 units and a dropout rate of 0.5, and the final dense layer has a number of units equal to the number of categories in the dataset, with a softmax activation function.","metadata":{}},{"cell_type":"code","source":"#Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:38:06.765068Z","iopub.execute_input":"2023-04-21T06:38:06.765903Z","iopub.status.idle":"2023-04-21T06:38:06.779744Z","shell.execute_reply.started":"2023-04-21T06:38:06.765848Z","shell.execute_reply":"2023-04-21T06:38:06.7784Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Train the model\nmodel.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:38:06.781695Z","iopub.execute_input":"2023-04-21T06:38:06.782531Z","iopub.status.idle":"2023-04-21T06:40:31.02427Z","shell.execute_reply.started":"2023-04-21T06:38:06.782492Z","shell.execute_reply":"2023-04-21T06:40:31.023341Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Evaluate the model on the test set\ntest_loss, test_acc = model.evaluate(X_test, y_test)\nprint(\"Test accuracy:\", test_acc)\n\n# Get the training accuracy from the history object\ntrain_acc = history.history['accuracy'][-1]\n\n# Print the training accuracy\nprint('Training accuracy:', train_acc)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:41:21.998701Z","iopub.execute_input":"2023-04-21T06:41:21.999227Z","iopub.status.idle":"2023-04-21T06:41:22.540247Z","shell.execute_reply.started":"2023-04-21T06:41:21.999184Z","shell.execute_reply":"2023-04-21T06:41:22.538789Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_two = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n    MaxPooling2D((2,2)),\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Conv2D(256, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Flatten(),\n    Dense(256, activation='relu'),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(len(categories), activation='softmax')\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:56:05.618977Z","iopub.execute_input":"2023-04-21T06:56:05.620249Z","iopub.status.idle":"2023-04-21T06:56:05.776694Z","shell.execute_reply.started":"2023-04-21T06:56:05.62019Z","shell.execute_reply":"2023-04-21T06:56:05.775118Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Two Explanantion \n\nThe model architecture defined above is a convolutional neural network (CNN) with four convolutional layers and four max pooling layers, followed by three dense layers. The first convolutional layer has 32 filters with a kernel size of (3,3), and the activation function used is ReLU. The input shape of the model is (150, 150, 3), which corresponds to the size of the images in the dataset. Each max pooling layer reduces the spatial dimensions of the feature maps by a factor of 2. After the final max pooling layer, the feature maps are flattened and passed through two dense layers with dropout regularization to prevent overfitting. The output layer has a softmax activation function and produces probabilities for each of the animal categories in the dataset.\n\nWhich Model to choose?\n\nThere could be several reasons why someone might use model_two instead of model. One possible reason is that model_two has more layers than model, which may make it more complex and potentially better at capturing the underlying patterns in the data. However, this also means that model_two may require more computational resources to train and may be more prone to overfitting if not regularized properly. Ultimately, the choice of which model to use would depend on the specific task and the trade-off between model complexity and performance.","metadata":{}},{"cell_type":"code","source":"# Compile the model\nmodel_two.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nhistory_two = model_two.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))\n\n# Evaluate the model\ntest_loss, test_acc = model_two.evaluate(X_test, y_test, verbose=2)\nprint('Test accuracy:', test_acc)\n\ntrain_acc = history_two.history['accuracy'][-1]\n\n# Print the training accuracy\nprint('Training accuracy:', train_acc)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T06:56:07.902199Z","iopub.execute_input":"2023-04-21T06:56:07.902623Z","iopub.status.idle":"2023-04-21T06:58:41.605483Z","shell.execute_reply.started":"2023-04-21T06:56:07.902585Z","shell.execute_reply":"2023-04-21T06:58:41.604223Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_three = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n    MaxPooling2D((2,2)),\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Flatten(),\n    Dropout(0.5),\n    Dense(512, activation='relu'),\n    Dense(len(categories), activation='softmax')\n])\n\n# Compile the model with categorical cross-entropy loss and Adam optimizer\nmodel_three.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:10:36.515322Z","iopub.execute_input":"2023-04-21T07:10:36.515802Z","iopub.status.idle":"2023-04-21T07:10:36.643041Z","shell.execute_reply.started":"2023-04-21T07:10:36.515757Z","shell.execute_reply":"2023-04-21T07:10:36.641884Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Train the model on the train set with batch size of 32, for 10 epochs\nmodel_three.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n\n# Evaluate the model on the test set\nloss, accuracy = model_three.evaluate(X_test, y_test)\nprint(\"Test accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:10:51.964309Z","iopub.execute_input":"2023-04-21T07:10:51.964748Z","iopub.status.idle":"2023-04-21T07:12:04.793147Z","shell.execute_reply.started":"2023-04-21T07:10:51.964711Z","shell.execute_reply":"2023-04-21T07:12:04.792109Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Augmentation - Possible ways to imporve the Image Classification","metadata":{}},{"cell_type":"code","source":"# Define an ImageDataGenerator for data augmentation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\n\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:15:57.619697Z","iopub.execute_input":"2023-04-21T07:15:57.620136Z","iopub.status.idle":"2023-04-21T07:15:57.626881Z","shell.execute_reply.started":"2023-04-21T07:15:57.620096Z","shell.execute_reply":"2023-04-21T07:15:57.625635Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocess the images in the train set\nX_train = np.array([preprocess_image(image_path) for image_path in train_data])\n\n# Create a flow from the ImageDataGenerator for data augmentation\nflow_train = datagen.flow(X_train, y_train, batch_size=32)\n\n# Preprocess the images in the test set\nX_test = np.array([preprocess_image(image_path) for image_path in test_data])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:16:16.702947Z","iopub.execute_input":"2023-04-21T07:16:16.703413Z","iopub.status.idle":"2023-04-21T07:16:17.644303Z","shell.execute_reply.started":"2023-04-21T07:16:16.703375Z","shell.execute_reply":"2023-04-21T07:16:17.64308Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_four = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n    MaxPooling2D((2,2)),\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Conv2D(256, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Conv2D(256, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Flatten(),\n    Dropout(0.5),\n    Dense(512, activation='relu'),\n    Dense(len(categories), activation='softmax')\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:16:36.064313Z","iopub.execute_input":"2023-04-21T07:16:36.064778Z","iopub.status.idle":"2023-04-21T07:16:36.209024Z","shell.execute_reply.started":"2023-04-21T07:16:36.064728Z","shell.execute_reply":"2023-04-21T07:16:36.20758Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_four.compile(\n    loss='categorical_crossentropy',\n    optimizer=Adam(lr=1e-4),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:16:53.435619Z","iopub.execute_input":"2023-04-21T07:16:53.43688Z","iopub.status.idle":"2023-04-21T07:16:53.451416Z","shell.execute_reply.started":"2023-04-21T07:16:53.436829Z","shell.execute_reply":"2023-04-21T07:16:53.450193Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the batch size and number of epochs\nbatch_size = 32\nepochs = 50\n\n# Fit the model on the training data with data augmentation\nhistory = model_four.fit(\n    datagen.flow(X_train, y_train, batch_size=batch_size),\n    steps_per_epoch=len(X_train) // batch_size,\n    epochs=epochs,\n    validation_data=(X_test, y_test)\n)\n\n# Evaluate the model on the test data\ntest_loss, test_acc = model_three.evaluate(X_test, y_test, verbose=2)\nprint(f\"Test accuracy: {test_acc:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:31:02.386253Z","iopub.execute_input":"2023-04-21T07:31:02.386746Z","iopub.status.idle":"2023-04-21T07:38:41.750065Z","shell.execute_reply.started":"2023-04-21T07:31:02.386702Z","shell.execute_reply":"2023-04-21T07:38:41.748958Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Explanation\n\nThe model_four is a convolutional neural network (CNN) model designed for image classification. It consists of several convolutional layers, max pooling layers, a flatten layer, dropout layer, and fully connected layers.\n\nThe first layer in the model is a 2D convolutional layer with 32 filters of size 3x3 and the ReLU activation function. It takes input images with a size of 150x150 pixels and 3 channels (RGB).\n\nThe second layer is a max pooling layer with a pool size of 2x2, which reduces the spatial dimensions of the output from the previous layer by half.\n\nThe third layer is another 2D convolutional layer with 64 filters of size 3x3 and the ReLU activation function, followed by another max pooling layer.\n\nThe fourth layer is a 2D convolutional layer with 128 filters of size 3x3 and the ReLU activation function, followed by another max pooling layer.\n\nThe fifth layer is a 2D convolutional layer with 256 filters of size 3x3 and the ReLU activation function, followed by another max pooling layer.\n\nThe sixth layer is another 2D convolutional layer with 256 filters of size 3x3 and the ReLU activation function, followed by another max pooling layer.\n\nThe seventh layer is a flatten layer that flattens the output from the previous layer into a 1D vector.\n\nThe eighth layer is a dropout layer that randomly drops out 50% of the connections during training to prevent overfitting.\n\nThe ninth layer is a fully connected layer with 512 neurons and the ReLU activation function.\n\nThe last layer is a fully connected layer with a number of neurons equal to the number of categories to classify, and the softmax activation function to output the probability distribution over the categories.\n\nOverall, this is a deep CNN architecture with multiple layers of convolution, pooling, and fully connected layers. It has a high number of filters in the convolutional layers, allowing it to learn more complex features in the images. The dropout layer is used to reduce overfitting, and the softmax output layer is used to produce the final classification probabilities.","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['loss'], label = 'loss')\nplt.xlabel('Epoch')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:44:09.315415Z","iopub.execute_input":"2023-04-21T07:44:09.315881Z","iopub.status.idle":"2023-04-21T07:44:09.493174Z","shell.execute_reply.started":"2023-04-21T07:44:09.315839Z","shell.execute_reply":"2023-04-21T07:44:09.491793Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_five = Sequential([\n    Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n    MaxPooling2D((2,2)),\n    Conv2D(32, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D((2,2)),\n    Flatten(),\n    Dense(64, activation='relu'),\n    Dense(len(categories), activation='softmax')\n])","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:51:29.915243Z","iopub.execute_input":"2023-04-21T07:51:29.916319Z","iopub.status.idle":"2023-04-21T07:51:30.030755Z","shell.execute_reply.started":"2023-04-21T07:51:29.916249Z","shell.execute_reply":"2023-04-21T07:51:30.02934Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This model includes three convolutional layers with increasing number of filters, each followed by max pooling. The output of the final convolutional layer is flattened and fed into two dense layers, with the last one having a number of neurons equal to the number of categories to be classified. The activation function for the final layer is softmax to output a probability distribution over the categories.","metadata":{}},{"cell_type":"code","source":"# compile the model\nmodel_five.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# train the model\nhistory = model_five.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n\n# evaluate the model\ntest_loss, test_acc = model_five.evaluate(X_test, y_test)\n\nprint('Test Loss:', test_loss)\nprint('Test Accuracy:', test_acc)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:51:42.735226Z","iopub.execute_input":"2023-04-21T07:51:42.735665Z","iopub.status.idle":"2023-04-21T07:52:25.622245Z","shell.execute_reply.started":"2023-04-21T07:51:42.735629Z","shell.execute_reply":"2023-04-21T07:52:25.620886Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Summary\nThe model was trained for 10 epochs with a training accuracy of 0.7417 and a validation accuracy of 0.2167. The test set was evaluated with a test accuracy of 0.2167 and a test loss of 2.7339. This indicates that the model is not generalizing well to new data and there is a high level of overfitting.","metadata":{}},{"cell_type":"code","source":"\n#Set the path to the image you want to classify\nimage_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Deer/5.jpg\"\n# Load the image and preprocess it\nimg = load_img(image_path, target_size=(150, 150))\nimg_array = img_to_array(img)\nimg_array /= 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Load the trained model\nmodel = model_five\n\n# Use the model to predict the category of the image\nprediction = model.predict(img_array)[0]\n\n# Get the category with the highest predicted probability\npredicted_category = categories[np.argmax(prediction)]\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(predicted_category)\nplt.show()\n\n# Print the predicted category\nprint(\"The predicted category is:\", predicted_category)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:54:03.284549Z","iopub.execute_input":"2023-04-21T07:54:03.285147Z","iopub.status.idle":"2023-04-21T07:54:03.584004Z","shell.execute_reply.started":"2023-04-21T07:54:03.285086Z","shell.execute_reply":"2023-04-21T07:54:03.582654Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#Set the path to the image you want to classify\nimage_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Bird/5.jpg\"\n# Load the image and preprocess it\nimg = load_img(image_path, target_size=(150, 150))\nimg_array = img_to_array(img)\nimg_array /= 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Load the trained model\nmodel = model_five\n\n# Use the model to predict the category of the image\nprediction = model.predict(img_array)[0]\n\n# Get the category with the highest predicted probability\npredicted_category = categories[np.argmax(prediction)]\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(predicted_category)\nplt.show()\n\n# Print the predicted category\nprint(\"The predicted category is:\", predicted_category)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:54:16.534706Z","iopub.execute_input":"2023-04-21T07:54:16.535206Z","iopub.status.idle":"2023-04-21T07:54:16.837444Z","shell.execute_reply.started":"2023-04-21T07:54:16.535163Z","shell.execute_reply":"2023-04-21T07:54:16.835894Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#Set the path to the image you want to classify\nimage_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Horse/30.jpg\"\n# Load the image and preprocess it\nimg = load_img(image_path, target_size=(150, 150))\nimg_array = img_to_array(img)\nimg_array /= 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Load the trained model\nmodel = model_five\n\n# Use the model to predict the category of the image\nprediction = model.predict(img_array)[0]\n\n# Get the category with the highest predicted probability\npredicted_category = categories[np.argmax(prediction)]\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(predicted_category)\nplt.show()\n\n# Print the predicted category\nprint(\"The predicted category is:\", predicted_category)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:55:19.201166Z","iopub.execute_input":"2023-04-21T07:55:19.201632Z","iopub.status.idle":"2023-04-21T07:55:19.505196Z","shell.execute_reply.started":"2023-04-21T07:55:19.201589Z","shell.execute_reply":"2023-04-21T07:55:19.503798Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.models import load_model\nimport matplotlib.pyplot as plt\n\n\n#Set the path to the image you want to classify\nimage_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Dog/5.jpg\"\n# Load the image and preprocess it\nimg = load_img(image_path, target_size=(150, 150))\nimg_array = img_to_array(img)\nimg_array /= 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Load the trained model\nmodel = model_five\n\n# Use the model to predict the category of the image\nprediction = model.predict(img_array)[0]\n\n# Get the category with the highest predicted probability\npredicted_category = categories[np.argmax(prediction)]\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(predicted_category)\nplt.show()\n\n# Print the predicted category\nprint(\"The predicted category is:\", predicted_category)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:52:44.052748Z","iopub.execute_input":"2023-04-21T07:52:44.053234Z","iopub.status.idle":"2023-04-21T07:52:44.335025Z","shell.execute_reply.started":"2023-04-21T07:52:44.05319Z","shell.execute_reply":"2023-04-21T07:52:44.333588Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# compile the model\nmodel_five.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# train the model\nhistory = model_five.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_test, y_test))\n\n# evaluate the model\ntest_loss, test_acc = model_five.evaluate(X_test, y_test)\n\nprint('Test Loss:', test_loss)\nprint('Test Accuracy:', test_acc)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T07:56:25.746262Z","iopub.execute_input":"2023-04-21T07:56:25.746777Z","iopub.status.idle":"2023-04-21T07:58:49.381939Z","shell.execute_reply.started":"2023-04-21T07:56:25.746736Z","shell.execute_reply":"2023-04-21T07:58:49.379106Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Summary\n\nThe model was trained for 30 epochs, and the last epoch's training accuracy was 100% and validation accuracy was 25%. The test accuracy after evaluating the model on test data was 25% with a test loss of 5.4038. This suggests that the model is overfitting to the training data and not generalizing well to the test data.","metadata":{}},{"cell_type":"code","source":"\n#Set the path to the image you want to classify\nimage_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Horse/25.jpg\"\n# Load the image and preprocess it\nimg = load_img(image_path, target_size=(150, 150))\nimg_array = img_to_array(img)\nimg_array /= 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Load the trained model\nmodel = model_five\n\n# Use the model to predict the category of the image\nprediction = model.predict(img_array)[0]\n\n# Get the category with the highest predicted probability\npredicted_category = categories[np.argmax(prediction)]\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(predicted_category)\nplt.show()\n\n# Print the predicted category\nprint(\"The predicted category is:\", predicted_category)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:00:18.717439Z","iopub.execute_input":"2023-04-21T08:00:18.717933Z","iopub.status.idle":"2023-04-21T08:00:19.097836Z","shell.execute_reply.started":"2023-04-21T08:00:18.717894Z","shell.execute_reply":"2023-04-21T08:00:19.096459Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#Set the path to the image you want to classify\nimage_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Deer/7.jpg\"\n# Load the image and preprocess it\nimg = load_img(image_path, target_size=(150, 150))\nimg_array = img_to_array(img)\nimg_array /= 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Load the trained model\nmodel = model_five\n\n# Use the model to predict the category of the image\nprediction = model.predict(img_array)[0]\n\n# Get the category with the highest predicted probability\npredicted_category = categories[np.argmax(prediction)]\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(predicted_category)\nplt.show()\n\n# Print the predicted category\nprint(\"The predicted category is:\", predicted_category)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:00:44.564776Z","iopub.execute_input":"2023-04-21T08:00:44.565227Z","iopub.status.idle":"2023-04-21T08:00:44.896437Z","shell.execute_reply.started":"2023-04-21T08:00:44.565185Z","shell.execute_reply":"2023-04-21T08:00:44.895122Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#Set the path to the image you want to classify\nimage_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Tiger/23.jpg\"\n# Load the image and preprocess it\nimg = load_img(image_path, target_size=(150, 150))\nimg_array = img_to_array(img)\nimg_array /= 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Load the trained model\nmodel = model_five\n\n# Use the model to predict the category of the image\nprediction = model.predict(img_array)[0]\n\n# Get the category with the highest predicted probability\npredicted_category = categories[np.argmax(prediction)]\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(predicted_category)\nplt.show()\n\n# Print the predicted category\nprint(\"The predicted category is:\", predicted_category)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:00:59.749945Z","iopub.execute_input":"2023-04-21T08:00:59.750463Z","iopub.status.idle":"2023-04-21T08:01:00.069167Z","shell.execute_reply.started":"2023-04-21T08:00:59.750419Z","shell.execute_reply":"2023-04-21T08:01:00.067393Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#Set the path to the image you want to classify\nimage_path = \"/kaggle/input/animal-classification-dataset-image-recognition/KaggleDataset/Lion/27.jpg\"\n# Load the image and preprocess it\nimg = load_img(image_path, target_size=(150, 150))\nimg_array = img_to_array(img)\nimg_array /= 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\n# Load the trained model\nmodel = model_five\n\n# Use the model to predict the category of the image\nprediction = model.predict(img_array)[0]\n\n# Get the category with the highest predicted probability\npredicted_category = categories[np.argmax(prediction)]\n\n# Display the image\nplt.imshow(img)\nplt.axis('off')\nplt.title(predicted_category)\nplt.show()\n\n# Print the predicted category\nprint(\"The predicted category is:\", predicted_category)","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:01:17.828015Z","iopub.execute_input":"2023-04-21T08:01:17.828542Z","iopub.status.idle":"2023-04-21T08:01:18.153447Z","shell.execute_reply.started":"2023-04-21T08:01:17.8285Z","shell.execute_reply":"2023-04-21T08:01:18.152152Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['loss'], label = 'loss')\nplt.xlabel('Epoch')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-21T08:05:01.509094Z","iopub.execute_input":"2023-04-21T08:05:01.509625Z","iopub.status.idle":"2023-04-21T08:05:01.750539Z","shell.execute_reply.started":"2023-04-21T08:05:01.509583Z","shell.execute_reply":"2023-04-21T08:05:01.749084Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Key Learnings: \n\nIn this project, we developed an image classification model to classify different animals based on their images. We used a dataset of animal images consisting of 10 different classes containing 300 images. All the images were collected from different sources over the net.\n\nWe preprocessed the data by resizing the images, splitting the data into training and testing sets, and normalizing the pixel values. We then built a Convolutional Neural Network (CNN) using the Keras framework to classify the images.\n\n\nOverall, we successfully developed an image classification model that could accurately classify different animals based on their images. The model's accuracy could be improved further by tuning the hyperparameters, using more data, or trying different architectures.","metadata":{}},{"cell_type":"markdown","source":"# Citations\n\n1. Numpy documentation: https://numpy.org/doc/\n2. Pandas documentation: https://pandas.pydata.org/docs/\n3. Matplotlib documentation: https://matplotlib.org/stable/contents.html\n4. Seaborn documentation: https://seaborn.pydata.org/index.html\n5. Sklearn documentation: https://scikit-learn.org/stable/\n6. Tensorflow documentation: https://www.tensorflow.org/api_docs\n7. Keras documentation: https://keras.io/api/\n8. OpenCV documentation: https://docs.opencv.org/\n9. Pillow documentation: https://pillow.readthedocs.io/en/stable/\n10. PyTorch documentation: https://pytorch.org/docs/stable/index.html\n11. Python documentation: https://docs.python.org/3/\n12. Stack Overflow: https://stackoverflow.com/\n13. Medium articles: https://medium.com/\n14. Towards Data Science articles: https://towardsdatascience.com/\n15. Machine Learning Mastery: https://machinelearningmastery.com/\n","metadata":{}},{"cell_type":"markdown","source":"# **Licences**\nLicences:\nMIT License\n\nCopyright (c) 2023 AI SkunkWorks, Muskan Srivastava\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","metadata":{}}]}